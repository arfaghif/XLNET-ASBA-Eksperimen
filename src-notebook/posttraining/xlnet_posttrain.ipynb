{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# INGET PAKE STD STEI\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afdb26Q5NowO",
        "outputId": "818e1431-7157-4255-bad4-c448f9b011aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQJ6MNi--OmH",
        "outputId": "09a548a6-1de7-40fc-e22e-8421aab4a265"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow-gpu==1.15.0"
      ],
      "metadata": {
        "id": "aZsFbCBN3ZT-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-tPEzSb3OnJr",
        "execution": {
          "iopub.status.busy": "2023-01-26T15:39:15.565861Z",
          "iopub.execute_input": "2023-01-26T15:39:15.566908Z",
          "iopub.status.idle": "2023-01-26T15:39:15.571645Z",
          "shell.execute_reply.started": "2023-01-26T15:39:15.566861Z",
          "shell.execute_reply": "2023-01-26T15:39:15.570712Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path_to_data='/content/drive/MyDrive/code/Data_Train/'\n",
        "# os.listdir(path_to_data)###"
      ],
      "metadata": {
        "id": "i2Cm9OREN-dZ",
        "execution": {
          "iopub.status.busy": "2023-01-26T15:40:05.233823Z",
          "iopub.execute_input": "2023-01-26T15:40:05.234584Z",
          "iopub.status.idle": "2023-01-26T15:40:05.239138Z",
          "shell.execute_reply.started": "2023-01-26T15:40:05.234536Z",
          "shell.execute_reply": "2023-01-26T15:40:05.238022Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2vuBVDK_PdfR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print (os.listdir(path_to_data))"
      ],
      "metadata": {
        "id": "JnusWpyZUH8Z",
        "execution": {
          "iopub.status.busy": "2023-01-26T15:40:09.654587Z",
          "iopub.execute_input": "2023-01-26T15:40:09.654970Z",
          "iopub.status.idle": "2023-01-26T15:40:09.675668Z",
          "shell.execute_reply.started": "2023-01-26T15:40:09.654938Z",
          "shell.execute_reply": "2023-01-26T15:40:09.674676Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##clone xlnet official repository\n",
        "!git clone https://github.com/arfaghif/malaya"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjeMg2YOMaet",
        "outputId": "ebc1bd36-a8a0-4c18-e538-4f0ffc9010ea",
        "execution": {
          "iopub.status.busy": "2023-01-26T15:40:32.864860Z",
          "iopub.execute_input": "2023-01-26T15:40:32.865211Z",
          "iopub.status.idle": "2023-01-26T15:40:41.306725Z",
          "shell.execute_reply.started": "2023-01-26T15:40:32.865183Z",
          "shell.execute_reply": "2023-01-26T15:40:41.305626Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'malaya'...\n",
            "remote: Enumerating objects: 17730, done.\u001b[K\n",
            "remote: Counting objects: 100% (17730/17730), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4520/4520), done.\u001b[K\n",
            "remote: Total 17730 (delta 12822), reused 17712 (delta 12814), pack-reused 0\n",
            "Receiving objects: 100% (17730/17730), 121.98 MiB | 16.62 MiB/s, done.\n",
            "Resolving deltas: 100% (12822/12822), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using sentence piece model from Google to tokenize text\n",
        "We will be using  Google's **sentencepiece** model to tokenize the text. "
      ],
      "metadata": {
        "id": "QMqY5nDTTJzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kubnGe9INpjF",
        "outputId": "0c9ceb35-79a4-4c55-b656-abdad82e6e69",
        "execution": {
          "iopub.status.busy": "2023-01-26T15:40:54.436630Z",
          "iopub.execute_input": "2023-01-26T15:40:54.437046Z",
          "iopub.status.idle": "2023-01-26T15:41:05.793743Z",
          "shell.execute_reply.started": "2023-01-26T15:40:54.437003Z",
          "shell.execute_reply": "2023-01-26T15:41:05.792607Z"
        },
        "trusted": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path_to_data"
      ],
      "metadata": {
        "id": "GBNWUd27VEZG",
        "execution": {
          "iopub.status.busy": "2023-01-26T15:41:08.338401Z",
          "iopub.execute_input": "2023-01-26T15:41:08.338858Z",
          "iopub.status.idle": "2023-01-26T15:41:08.347768Z",
          "shell.execute_reply.started": "2023-01-26T15:41:08.338789Z",
          "shell.execute_reply": "2023-01-26T15:41:08.346838Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_dir=os.getcwd()"
      ],
      "metadata": {
        "id": "EHjlrWlvVbvW",
        "execution": {
          "iopub.status.busy": "2023-01-26T15:41:13.361284Z",
          "iopub.execute_input": "2023-01-26T15:41:13.361662Z",
          "iopub.status.idle": "2023-01-26T15:41:13.366956Z",
          "shell.execute_reply.started": "2023-01-26T15:41:13.361629Z",
          "shell.execute_reply": "2023-01-26T15:41:13.365782Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_dir"
      ],
      "metadata": {
        "id": "ys5gqn2IWARA",
        "execution": {
          "iopub.status.busy": "2023-01-26T15:41:16.512690Z",
          "iopub.execute_input": "2023-01-26T15:41:16.513365Z",
          "iopub.status.idle": "2023-01-26T15:41:16.520481Z",
          "shell.execute_reply.started": "2023-01-26T15:41:16.513329Z",
          "shell.execute_reply": "2023-01-26T15:41:16.519548Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b85c6063-8dfa-4752-acc4-f7e2bb703f02"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/code/Finetuning/new'"
      ],
      "metadata": {
        "id": "wIQgYvcoVr4a",
        "execution": {
          "iopub.status.busy": "2023-01-26T15:42:02.593903Z",
          "iopub.execute_input": "2023-01-26T15:42:02.594335Z",
          "iopub.status.idle": "2023-01-26T15:42:02.604093Z",
          "shell.execute_reply.started": "2023-01-26T15:42:02.594298Z",
          "shell.execute_reply": "2023-01-26T15:42:02.602944Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8ae751-b73d-4e47-cca5-93b6d43b1405"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/code/Finetuning/new\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "7LL3K9hnMEN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7cc4df-195f-4539-f8ff-8eda4feb18a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "airy_car_corpus.txt   all_corpus.txt\t\tcar_corpus.txt\n",
            "airy_corpus.txt       all_sp10m.cased.v3.model\tcar_rest_corpus.txt\n",
            "airy_rest_corpus.txt  all_sp10m.cased.v3.vocab\trest_corpus.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be keeping vocab_size to 12000 and unigram model."
      ],
      "metadata": {
        "id": "t51ch6_o3ZUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # spm_train --input=data_lm.txt --model_prefix=sp10m.cased.v3 \n",
        "# # --vocab_size=12000 --character_coverage=0.99995 --model_type=unigram\n",
        "import sentencepiece as spm\n",
        "spm.SentencePieceTrainer.Train('--input=airy_corpus.txt  --vocab_size=10175 --model_prefix=all_sp10m.cased.v3 --character_coverage=0.99995 --model_type=unigram')\n"
      ],
      "metadata": {
        "id": "1UnBcVQNTXRE",
        "execution": {
          "iopub.status.busy": "2023-01-26T15:45:22.400007Z",
          "iopub.execute_input": "2023-01-26T15:45:22.400399Z",
          "iopub.status.idle": "2023-01-26T15:45:24.107786Z",
          "shell.execute_reply.started": "2023-01-26T15:45:22.400368Z",
          "shell.execute_reply": "2023-01-26T15:45:24.104329Z"
        },
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(path_to_data)##now sentence piece model has been saved"
      ],
      "metadata": {
        "id": "bN6EdHmpUeGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content'"
      ],
      "metadata": {
        "id": "Th3DaWoScM4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/malaya/pretrained-model/xlnet'"
      ],
      "metadata": {
        "id": "jo9Jk41VcQAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (os.listdir(path_to_data + \"corpus/\"))"
      ],
      "metadata": {
        "id": "lr8ZcqKOcv3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##We will be saving tf records in a folder named experimenttfrecords"
      ],
      "metadata": {
        "id": "lOKRSWxoeR9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prepro_utils.py\n",
        "# coding=utf-8\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import unicodedata\n",
        "import six\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "SPIECE_UNDERLINE = '▁'\n",
        "\n",
        "\n",
        "def printable_text(text):\n",
        "  \"\"\"Returns text encoded in a way suitable for print or `tf.logging`.\"\"\"\n",
        "\n",
        "  # These functions want `str` for both Python2 and Python3, but in one case\n",
        "  # it's a Unicode string and in the other it's a byte string.\n",
        "  if six.PY3:\n",
        "    if isinstance(text, str):\n",
        "      return text\n",
        "    elif isinstance(text, bytes):\n",
        "      return text.decode(\"utf-8\", \"ignore\")\n",
        "    else:\n",
        "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
        "  elif six.PY2:\n",
        "    if isinstance(text, str):\n",
        "      return text\n",
        "    elif isinstance(text, unicode):\n",
        "      return text.encode(\"utf-8\")\n",
        "    else:\n",
        "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
        "  else:\n",
        "    raise ValueError(\"Not running on Python2 or Python 3?\")\n",
        "\n",
        "\n",
        "def print_(*args):\n",
        "  new_args = []\n",
        "  for arg in args:\n",
        "    if isinstance(arg, list):\n",
        "      s = [printable_text(i) for i in arg]\n",
        "      s = ' '.join(s)\n",
        "      new_args.append(s)\n",
        "    else:\n",
        "      new_args.append(printable_text(arg))\n",
        "  print(*new_args)\n",
        "\n",
        "\n",
        "def preprocess_text(inputs, lower=False, remove_space=True, keep_accents=False):\n",
        "  if remove_space:\n",
        "    outputs = ' '.join(inputs.strip().split())\n",
        "  else:\n",
        "    outputs = inputs\n",
        "  outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n",
        "\n",
        "  if six.PY2 and isinstance(outputs, str):\n",
        "    outputs = outputs.decode('utf-8')\n",
        "\n",
        "  if not keep_accents:\n",
        "    outputs = unicodedata.normalize('NFKD', outputs)\n",
        "    outputs = ''.join([c for c in outputs if not unicodedata.combining(c)])\n",
        "  if lower:\n",
        "    outputs = outputs.lower()\n",
        "\n",
        "  return outputs\n",
        "\n",
        "\n",
        "def encode_pieces(sp_model, text, return_unicode=True, sample=False):\n",
        "  # return_unicode is used only for py2\n",
        "\n",
        "  # note(zhiliny): in some systems, sentencepiece only accepts str for py2\n",
        "  if six.PY2 and isinstance(text, unicode):\n",
        "    text = text.encode('utf-8')\n",
        "\n",
        "  if not sample:\n",
        "    pieces = sp_model.EncodeAsPieces(text)\n",
        "  else:\n",
        "    pieces = sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n",
        "  new_pieces = []\n",
        "  for piece in pieces:\n",
        "    if len(piece) > 1 and piece[-1] == ',' and piece[-2].isdigit():\n",
        "      cur_pieces = sp_model.EncodeAsPieces(\n",
        "          piece[:-1].replace(SPIECE_UNDERLINE, ''))\n",
        "      if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n",
        "        if len(cur_pieces[0]) == 1:\n",
        "          cur_pieces = cur_pieces[1:]\n",
        "        else:\n",
        "          cur_pieces[0] = cur_pieces[0][1:]\n",
        "      cur_pieces.append(piece[-1])\n",
        "      new_pieces.extend(cur_pieces)\n",
        "    else:\n",
        "      new_pieces.append(piece)\n",
        "\n",
        "  # note(zhiliny): convert back to unicode for py2\n",
        "  if six.PY2 and return_unicode:\n",
        "    ret_pieces = []\n",
        "    for piece in new_pieces:\n",
        "      if isinstance(piece, str):\n",
        "        piece = piece.decode('utf-8')\n",
        "      ret_pieces.append(piece)\n",
        "    new_pieces = ret_pieces\n",
        "\n",
        "  return new_pieces\n",
        "\n",
        "\n",
        "def encode_ids(sp_model, text, sample=False):\n",
        "  pieces = encode_pieces(sp_model, text, return_unicode=False, sample=sample)\n",
        "  ids = [sp_model.PieceToId(piece) for piece in pieces]\n",
        "  return ids\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  import sentencepiece as spm\n",
        "\n",
        "  sp = spm.SentencePieceProcessor()\n",
        "  sp.load('sp10m.uncased.v3.model')\n",
        "\n",
        "  print_(u'I was born in 2000, and this is falsé.')\n",
        "  print_(u'ORIGINAL', sp.EncodeAsPieces(u'I was born in 2000, and this is falsé.'))\n",
        "  print_(u'OURS', encode_pieces(sp, u'I was born in 2000, and this is falsé.'))\n",
        "  print(encode_ids(sp, u'I was born in 2000, and this is falsé.'))\n",
        "  print_('')\n",
        "  prepro_func = partial(preprocess_text, lower=True)\n",
        "  print_(prepro_func('I was born in 2000, and this is falsé.'))\n",
        "  print_('ORIGINAL', sp.EncodeAsPieces(prepro_func('I was born in 2000, and this is falsé.')))\n",
        "  print_('OURS', encode_pieces(sp, prepro_func('I was born in 2000, and this is falsé.')))\n",
        "  print(encode_ids(sp, prepro_func('I was born in 2000, and this is falsé.')))\n",
        "  print_('')\n",
        "  print_('I was born in 2000, and this is falsé.')\n",
        "  print_('ORIGINAL', sp.EncodeAsPieces('I was born in 2000, and this is falsé.'))\n",
        "  print_('OURS', encode_pieces(sp, 'I was born in 2000, and this is falsé.'))\n",
        "  print(encode_ids(sp, 'I was born in 2000, and this is falsé.'))\n",
        "  print_('')\n",
        "  print_('I was born in 92000, and this is falsé.')\n",
        "  print_('ORIGINAL', sp.EncodeAsPieces('I was born in 92000, and this is falsé.'))\n",
        "  print_('OURS', encode_pieces(sp, 'I was born in 92000, and this is falsé.'))\n",
        "  print(encode_ids(sp, 'I was born in 92000, and this is falsé.'))"
      ],
      "metadata": {
        "id": "TBWEkO4UDubs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git pull"
      ],
      "metadata": {
        "id": "raj3QlKxCsyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_utils.py \\\n",
        "   --use_tpu=False \\\n",
        "   --bsz_per_host=8 \\\n",
        "   --num_core_per_host=1 \\\n",
        "   --uncased=False \\\n",
        "   --seq_len=128 \\\n",
        "   --reuse_len=64 \\\n",
        "   --input_glob=\"/content/drive/MyDrive/code/Data_Train/corpus/airy_corpus.txt\" \\\n",
        "   --save_dir=\"/content/drive/MyDrive/TA/code/finetune/airy_corpus_finetune\" \\\n",
        "   --sp_path=\"/content/drive/MyDrive/code/Data_Train/corpus/sp10m.cased.v3.model\" \\\n",
        "   --mask_alpha=6 --mask_beta=1 --num_predict=85 --bi_data=False"
      ],
      "metadata": {
        "id": "9tdj2aqaciFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, it's time to train the model."
      ],
      "metadata": {
        "id": "yjcbRsTlnG8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "id": "IdG9xgAxnMKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/malaya/pretrained-model/xlnet"
      ],
      "metadata": {
        "id": "T6qDrgZ5Mgx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hK2tFCCVE2lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://f000.backblazeb2.com/file/malaya-model/bert-bahasa/xlnet-base-29-03-2020.tar.gz"
      ],
      "metadata": {
        "id": "iy5EeB1UnPBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar -xvf xlnet-base-29-03-2020.tar.gz"
      ],
      "metadata": {
        "id": "2l1O2HsQnZCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  We will be training our language model from checkpoint. Checkpoint is the model downloaded above.\n",
        "\n",
        "We will save the newly trained model inside the directoy experimenttfrecords created above. If we omit init_checkpoint argument we will get freshly trained language model."
      ],
      "metadata": {
        "id": "Saeqlvsz3ZUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r 'xlnet-base-29-03-2020' '/content/drive/My Drive/code'"
      ],
      "metadata": {
        "id": "P_7LIlqn6BPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git pull"
      ],
      "metadata": {
        "id": "5wik2QAgIHUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lmSIwaNlI1UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://storage.googleapis.com/xlnet/released_models/cased_L-12_H-768_A-12.zip"
      ],
      "metadata": {
        "id": "QDyaczCnIXfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip cased_L-12_H-768_A-12.zip"
      ],
      "metadata": {
        "id": "XyxJY3b4IdE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_gpu.py \\\n",
        "   --corpus_info_path=\"/content/drive/MyDrive/TA/code/finetune/airy_corpus_finetune/corpus_info.json\" \\\n",
        "   --model_dir=\"/content/drive/MyDrive/TA/code/finetune/airy_corpus_finetune/model\"  \\\n",
        "   --record_info_dir=\"/content/drive/MyDrive/TA/code/finetune/airy_corpus_finetune/tfrecords\" \\\n",
        "   --train_batch_size=8 \\\n",
        "   --seq_len=128 \\\n",
        "   --reuse_len=64 \\ \n",
        "   --mem_len=384 \\\n",
        "   --perm_size=256 \\\n",
        "   --untie_r=True \\\n",
        "   --mask_alpha=6 \\\n",
        "   --mask_beta=1 \\\n",
        "   --num_predict=85 \\\n",
        "   --train_steps=100 \\\n",
        "   --iterations=2 \\\n",
        "   --uncased=False \\\n",
        "   --bi_data=False \\\n",
        "   --save_steps=2 \\\n",
        "   --d_head=64 \\\n",
        "   --d_inner=3072 \\\n",
        "   --d_model=768 \\\n",
        "   --ff_activation=gelu \\\n",
        "   --n_head=12 \\\n",
        "   --n_layer=12 \\\n",
        "   --n_token=32000 \\\n",
        "   --init_checkpoint='/content/drive/My Drive/code/xlnet-base-29-03-2020/model.ckpt-300000'"
      ],
      "metadata": {
        "id": "cDjrUznWnjH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 train_gpu.py \\\n",
        "#   --corpus_info_path=\"/kaggle/working/experimenttfrecords/corpus_info.json\" \\\n",
        "#   --record_info_dir=\"/content/drive/My Drive/experimenttfrecords/tfrecords\" \\\n",
        "#   --train_batch_size=20 \\\n",
        "#   --seq_len=512 \\\n",
        "#   --reuse_len=256 \\\n",
        "#   --mem_len=384 \\\n",
        "#   --perm_size=256 \\\n",
        "#   --n_layer=12 \\\n",
        "#   --d_model=768 \\\n",
        "#   --d_embed=768 \\\n",
        "#   --n_head=12 \\\n",
        "#   --d_head=64 \\\n",
        "#   --d_inner=3072 \\\n",
        "#   --untie_r=True \\\n",
        "#   --mask_alpha=6 \\\n",
        "#   --mask_beta=1 \\\n",
        "#   --num_predict=85 \\\n",
        "#   --model_dir=output-model \\\n",
        "#   --uncased=False \\\n",
        "#   --num_core_per_host=1 \\\n",
        "#   --train_steps=20000  --iterations=10 --learning_rate=5e-5 \\\n",
        "#   --num_gpu_cores=2"
      ],
      "metadata": {
        "id": "WCvDY267maff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/'"
      ],
      "metadata": {
        "id": "t0aLCihhsZ7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\"/content/drive/MyDrive/TA/code/finetune/experimenttfrecords/model"
      ],
      "metadata": {
        "id": "bwLz8LzlSJlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "id": "eNaKd4YP0o8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting tensorflow model into pytorch model"
      ],
      "metadata": {
        "id": "eJHfzqtC06d-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# export TRANSFO_XL_CHECKPOINT_PATH='base_cased/model.ckpt'\n",
        "# export TRANSFO_XL_CONFIG_PATH='base_cased/config.json '\n",
        "\n",
        "# python transformers-cli convert --model_type xlnet  --tf_checkpoint $TRANSFO_XL_CHECKPOINT_PATH --config $TRANSFO_XL_CONFIG_PATH --pytorch_dump_output xlnet_exp_pytorch\n"
      ],
      "metadata": {
        "id": "1dW-Lwjz0wx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/transformers/'"
      ],
      "metadata": {
        "id": "6WJVffdg1-D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export TRANSFO_XL_CHECKPOINT_PATH='/content/drive/MyDrive/TA/code/finetune/airy_corpus_finetune/model/model.ckpt'\n",
        "!export TRANSFO_XL_CONFIG_PATH='/content/drive/MyDrive/TA/code/finetune/airy_corpus_finetune/model/config.json'\n",
        "!export PYTORCH_MODELPATH='/content/drive/MyDrive/TA/code/finetune/airy_corpus_finetune/pytorch_model'"
      ],
      "metadata": {
        "id": "MzWleP2a2Alq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "chsE777j3Jor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 transformers-cli convert \\\n",
        "    --model_type xlnet  \\\n",
        "    --tf_checkpoint=\"/content/drive/MyDrive/TA/code/finetune/airy_corpus_finetune/model/model.ckpt\" \\\n",
        "    --config=\"/content/drive/MyDrive/TA/code/finetune/airy_corpus_finetune/model/config.json\" \\\n",
        "    --pytorch_dump_output='/content/drive/MyDrive/TA/code/finetune/airy_corpus_finetune/pytorch_model'"
      ],
      "metadata": {
        "id": "ERYiRufA2ijB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8vZIt4PU4U_I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}